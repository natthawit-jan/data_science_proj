{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/natthawit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/natthawit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/natthawit/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenized sentences should not contain stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function to get random wikipedia link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_url():\n",
    "    random_url = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
    "    response = requests.get(random_url)\n",
    "    return response.url\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate 200 random links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [get_random_url() for i in range(200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the contents from all those links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wikipedia(url):\n",
    "    # Send a request to the URL\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Parse the page content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract the title of the page\n",
    "    title = soup.find(id='firstHeading').text\n",
    "    texts = []\n",
    "    # Extract the content of the page\n",
    "    contents = soup.find_all('div', class_='mw-parser-output')\n",
    "    for c in contents:\n",
    "        for found_content in c.find_all(['p', 'h2', 'h3', 'h4', 'ul', 'ol']):  \n",
    "            texts.append(found_content.text)\n",
    "    return title, texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cleaned_texts = []\n",
    "\n",
    "for url in urls:\n",
    "    title, paragraphs = scrape_wikipedia(url)\n",
    "    all_cleaned_texts.append({'title': title, 'url': url, 'content': paragraphs})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'The Quick and the Dead (1963 film)',\n",
       " 'url': 'https://en.wikipedia.org/wiki/The_Quick_and_the_Dead_(1963_film)',\n",
       " 'content': ['1963\\xa0(1963)',\n",
       "  'The Quick and the Dead is a 1963 war film directed by Robert Totten, set in Nazi-occupied Europe during World War II.[1][2][3][4]\\n',\n",
       "  'Plot',\n",
       "  'A group of American soldiers and Italian partisans during World War II join forces in northern Italy against the Germans.\\n',\n",
       "  'Cast',\n",
       "  \"Victor French as Milo Riley\\nMajel Barrett as Teresa\\nLouis Massad as Donatelli\\nSandy Donigan as Maria\\nJames Almanzar as Giorgio\\nLarry Mann as Parker\\nJon Cedar as Lt. Rogers\\nJoe Folino as American Soldier\\nGerald Ervin as  American Soldier\\nJoseph Locastro as Giovanni\\nWilliam Kirschner as Dr. Romano\\nFrank D'Agostino as Priest\\nStuart Nisbet as Nazi Officer\\nTed French as Old Man\\nJack Crawford as American Officer\\nRobert Harker as German Officer\",\n",
       "  'References',\n",
       "  'Citations',\n",
       "  '\\n^ The Quick and the Dead. AllMovie. 1963. {{cite book}}: |website= ignored (help)\\n\\n^ The Quick and the Dead. Turner Classic Movies. 1963.\\n\\n^ Brode, Douglas (2020). From Hell To Hollywood: An Encyclopedia of World War II Films. Albany, Georgia: BearManor Media. ISBN\\xa0978-1629335216.\\n\\n^ Craig 2019, p.\\xa0301.\\n\\n',\n",
       "  'Sources',\n",
       "  'Craig, Rob (2019). American International Pictures: A Comprehensive Filmography. New York City: McFarland & Company. p.\\xa0301. ISBN\\xa0978-1476666310.',\n",
       "  'External links',\n",
       "  'The Quick and the Dead at IMDb\\nThe Quick and the Dead at AllMovie\\nThe Quick and the Dead at the TCM Movie Database\\nThe Quick and the Dead at the AFI Catalog of Feature Films',\n",
       "  '\\n',\n",
       "  'This article about a film on World War II is a stub. You can help Wikipedia by expanding it.',\n",
       "  'vte']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cleaned_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean unneccessary texts ( new line, reference number, extra spaces, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    text = re.sub(r\"'s\", '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "for obj in all_cleaned_texts:\n",
    "    title, url, contents_lst = obj.values()\n",
    "    big_string = \" \".join(contents_lst).strip()\n",
    "    obj['joined_text'] = clean_text(big_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the text using nltk.tokenize (Standard lib for tokenize English word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens =  word_tokenize(text)\n",
    "    return [word.lower() for word in tokens if word.lower() not in stop_words and re.match(r'^[a-zA-Z]+$', word) and len(word) > 2]\n",
    "\n",
    "texts = [obj['joined_text'] for obj in all_cleaned_texts]\n",
    "tokenized_texts = [\" | \".join(tokenize(text)) for text in texts]\n",
    "titles = [obj['title'] for obj in all_cleaned_texts]\n",
    "\n",
    "\n",
    "pd.DataFrame([(i[0], i[1], i[2]) for i in zip(texts, tokenized_texts, titles)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make TfidVectorizer for all those tokenized texts to see the text frequency in each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natthawit/miniconda3/envs/Olympics/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 27985)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aab</th>\n",
       "      <th>aadaab</th>\n",
       "      <th>aadam</th>\n",
       "      <th>aadmi</th>\n",
       "      <th>aadt</th>\n",
       "      <th>aakhar</th>\n",
       "      <th>aalejivabhai</th>\n",
       "      <th>aali</th>\n",
       "      <th>aalok</th>\n",
       "      <th>aamaaloarkaan</th>\n",
       "      <th>...</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zum</th>\n",
       "      <th>zumar</th>\n",
       "      <th>zumberge</th>\n",
       "      <th>zundapp</th>\n",
       "      <th>zur</th>\n",
       "      <th>zurr</th>\n",
       "      <th>zuyevo</th>\n",
       "      <th>zvezda</th>\n",
       "      <th>zyrin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27985 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aab  aadaab  aadam  aadmi  aadt  aakhar  aalejivabhai  aali  aalok  \\\n",
       "0  0.0     0.0    0.0    0.0   0.0     0.0           0.0   0.0    0.0   \n",
       "1  0.0     0.0    0.0    0.0   0.0     0.0           0.0   0.0    0.0   \n",
       "2  0.0     0.0    0.0    0.0   0.0     0.0           0.0   0.0    0.0   \n",
       "3  0.0     0.0    0.0    0.0   0.0     0.0           0.0   0.0    0.0   \n",
       "4  0.0     0.0    0.0    0.0   0.0     0.0           0.0   0.0    0.0   \n",
       "\n",
       "   aamaaloarkaan  ...  zulu  zum  zumar  zumberge  zundapp  zur  zurr  zuyevo  \\\n",
       "0            0.0  ...   0.0  0.0    0.0       0.0      0.0  0.0   0.0     0.0   \n",
       "1            0.0  ...   0.0  0.0    0.0       0.0      0.0  0.0   0.0     0.0   \n",
       "2            0.0  ...   0.0  0.0    0.0       0.0      0.0  0.0   0.0     0.0   \n",
       "3            0.0  ...   0.0  0.0    0.0       0.0      0.0  0.0   0.0     0.0   \n",
       "4            0.0  ...   0.0  0.0    0.0       0.0      0.0  0.0   0.0     0.0   \n",
       "\n",
       "   zvezda  zyrin  \n",
       "0     0.0    0.0  \n",
       "1     0.0    0.0  \n",
       "2     0.0    0.0  \n",
       "3     0.0    0.0  \n",
       "4     0.0    0.0  \n",
       "\n",
       "[5 rows x 27985 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
    "tfidf_matrix= vectorizer.fit_transform(texts)\n",
    "print(tfidf_matrix.shape)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a number of topics for the model to try figuring out. ( this is the random choice, the more topics, the less generalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_NUMBER = 5\n",
    "PREDICT_THRESHOLD = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Singular Value Decomposition to calculate the relation between all these documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=TOPIC_NUMBER, algorithm='randomized', n_iter=5000)\n",
    "lsa = svd_model.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe that shows the amount of confidence each document belongs to each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.134910</td>\n",
       "      <td>-0.073099</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>-0.054377</td>\n",
       "      <td>-0.021944</td>\n",
       "      <td>The Quick and the Dead is a  war film direct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.128489</td>\n",
       "      <td>-0.075861</td>\n",
       "      <td>-0.070900</td>\n",
       "      <td>0.242133</td>\n",
       "      <td>0.035059</td>\n",
       "      <td>During the – Portuguese football season FC Por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.101753</td>\n",
       "      <td>-0.087392</td>\n",
       "      <td>0.415259</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>-0.039876</td>\n",
       "      <td>Neoparaphytoseius sooretamus is a species of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.134862</td>\n",
       "      <td>-0.018495</td>\n",
       "      <td>-0.020146</td>\n",
       "      <td>-0.130587</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>Sengundram known in English as Red Hills is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069815</td>\n",
       "      <td>-0.050815</td>\n",
       "      <td>0.230792</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>Eleutherodactylus brevipalmatus Eleutherodacty...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_0   topic_1   topic_2   topic_3   topic_4  \\\n",
       "0  0.134910 -0.073099  0.005402 -0.054377 -0.021944   \n",
       "1  0.128489 -0.075861 -0.070900  0.242133  0.035059   \n",
       "2  0.101753 -0.087392  0.415259  0.027033 -0.039876   \n",
       "3  0.134862 -0.018495 -0.020146 -0.130587  0.018018   \n",
       "4  0.069815 -0.050815  0.230792  0.000797 -0.022529   \n",
       "\n",
       "                                                text  \n",
       "0    The Quick and the Dead is a  war film direct...  \n",
       "1  During the – Portuguese football season FC Por...  \n",
       "2  Neoparaphytoseius sooretamus is a species of m...  \n",
       "3  Sengundram known in English as Red Hills is a ...  \n",
       "4  Eleutherodactylus brevipalmatus Eleutherodacty...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_to_topics = pd.DataFrame(lsa, columns=[f\"topic_{i}\" for i in range(TOPIC_NUMBER)])\n",
    "documents_to_topics = documents_to_topics.assign(text=texts)\n",
    "documents_to_topics.head()\n",
    "# Assuming all_cleaned_texts is a list of dictionaries with 'joined_text' as one of the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 27985)\n"
     ]
    }
   ],
   "source": [
    "# for each feature words, what are the components of each topic\n",
    "components = svd_model.components_\n",
    "print(components.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign the topic to the word ( the highest score is the main topic, the lesser one can be thought of as sub topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aab</th>\n",
       "      <th>aadaab</th>\n",
       "      <th>aadam</th>\n",
       "      <th>aadmi</th>\n",
       "      <th>aadt</th>\n",
       "      <th>aakhar</th>\n",
       "      <th>aalejivabhai</th>\n",
       "      <th>aali</th>\n",
       "      <th>aalok</th>\n",
       "      <th>aamaaloarkaan</th>\n",
       "      <th>...</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zum</th>\n",
       "      <th>zumar</th>\n",
       "      <th>zumberge</th>\n",
       "      <th>zundapp</th>\n",
       "      <th>zur</th>\n",
       "      <th>zurr</th>\n",
       "      <th>zuyevo</th>\n",
       "      <th>zvezda</th>\n",
       "      <th>zyrin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic_0</th>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_1</th>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.000956</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000764</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.001797</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>-0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_2</th>\n",
       "      <td>0.000110</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>-0.000384</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>-0.001107</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>-0.000384</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>-0.001097</td>\n",
       "      <td>-0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_3</th>\n",
       "      <td>-0.000978</td>\n",
       "      <td>-0.000776</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>-0.003191</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>-0.000810</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>-0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_4</th>\n",
       "      <td>0.004717</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.000324</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000784</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.000324</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>-0.000324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27985 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aab    aadaab     aadam     aadmi      aadt    aakhar  \\\n",
       "topic_0  0.000590  0.000546  0.000452  0.000273  0.001113  0.000273   \n",
       "topic_1 -0.000080 -0.000451 -0.000400 -0.000225  0.000268 -0.000225   \n",
       "topic_2  0.000110 -0.000337 -0.000384 -0.000168 -0.000259 -0.000168   \n",
       "topic_3 -0.000978 -0.000776 -0.000161 -0.000388 -0.003191 -0.000388   \n",
       "topic_4  0.004717 -0.000093 -0.000324 -0.000047  0.000143 -0.000047   \n",
       "\n",
       "         aalejivabhai      aali     aalok  aamaaloarkaan  ...      zulu  \\\n",
       "topic_0      0.000273  0.000273  0.000986       0.000273  ...  0.000945   \n",
       "topic_1     -0.000225 -0.000225 -0.000956      -0.000225  ... -0.000764   \n",
       "topic_2     -0.000168 -0.000168 -0.000733      -0.000168  ...  0.000415   \n",
       "topic_3     -0.000388 -0.000388 -0.000996      -0.000388  ... -0.000533   \n",
       "topic_4     -0.000047 -0.000047 -0.000784      -0.000047  ... -0.000073   \n",
       "\n",
       "              zum     zumar  zumberge   zundapp       zur      zurr    zuyevo  \\\n",
       "topic_0  0.000162  0.000463  0.000383  0.001856  0.000383  0.000452  0.000350   \n",
       "topic_1 -0.000122 -0.000274 -0.000241 -0.001797 -0.000241 -0.000400 -0.000062   \n",
       "topic_2 -0.000098 -0.000304  0.000304 -0.001107  0.000304 -0.000384  0.000759   \n",
       "topic_3 -0.000181 -0.000810 -0.000432 -0.000390 -0.000432 -0.000161 -0.000389   \n",
       "topic_4 -0.000084  0.000077 -0.000292 -0.000223 -0.000292 -0.000324  0.001184   \n",
       "\n",
       "           zvezda     zyrin  \n",
       "topic_0  0.000902  0.000452  \n",
       "topic_1 -0.001203 -0.000400  \n",
       "topic_2 -0.001097 -0.000384  \n",
       "topic_3  0.003104 -0.000161  \n",
       "topic_4  0.000397 -0.000324  \n",
       "\n",
       "[5 rows x 27985 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_matrix = pd.DataFrame(components, columns=feature_names, index=[f\"topic_{i}\" for i in range(TOPIC_NUMBER)])\n",
    "encoding_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for topic 0\n",
      "retrieved    0.229227\n",
      "historic     0.224548\n",
      "national     0.221534\n",
      "register     0.177863\n",
      "places       0.139340\n",
      "Name: topic_0, dtype: float64\n",
      "\n",
      "\n",
      "Top words for topic 1\n",
      "historic    0.444433\n",
      "register    0.349182\n",
      "national    0.287509\n",
      "places      0.273903\n",
      "property    0.109765\n",
      "Name: topic_1, dtype: float64\n",
      "\n",
      "\n",
      "Top words for topic 2\n",
      "species     0.261748\n",
      "gbif        0.230339\n",
      "wikidata    0.211266\n",
      "col         0.177706\n",
      "tree        0.163949\n",
      "Name: topic_2, dtype: float64\n",
      "\n",
      "\n",
      "Top words for topic 3\n",
      "league      0.238313\n",
      "uefa        0.226159\n",
      "football    0.202289\n",
      "team        0.180464\n",
      "season      0.151612\n",
      "Name: topic_3, dtype: float64\n",
      "\n",
      "\n",
      "Top words for topic 4\n",
      "kola        0.663947\n",
      "mahalleh    0.233338\n",
      "bala        0.190631\n",
      "pain        0.187329\n",
      "sar         0.136821\n",
      "Name: topic_4, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(TOPIC_NUMBER):\n",
    "    print(f\"Top words for topic {i}\")\n",
    "    print(encoding_matrix.iloc[i].sort_values(ascending=False).head(5))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally assign the original documents to the topic name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['topic_0', 'topic_1', 'topic_2', 'topic_3', 'topic_4', 'text', 'topic',\n",
      "       'topic_score', 'topic_text', 'WIKI_TITLE'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_score</th>\n",
       "      <th>topic_text</th>\n",
       "      <th>WIKI_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.134910</td>\n",
       "      <td>-0.073099</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>-0.054377</td>\n",
       "      <td>-0.021944</td>\n",
       "      <td>The Quick and the Dead is a  war film direct...</td>\n",
       "      <td>topic_0</td>\n",
       "      <td>0.134910</td>\n",
       "      <td>[retrieved, historic, national, register, places]</td>\n",
       "      <td>The Quick and the Dead (1963 film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.128489</td>\n",
       "      <td>-0.075861</td>\n",
       "      <td>-0.070900</td>\n",
       "      <td>0.242133</td>\n",
       "      <td>0.035059</td>\n",
       "      <td>During the – Portuguese football season FC Por...</td>\n",
       "      <td>topic_3</td>\n",
       "      <td>0.242133</td>\n",
       "      <td>[league, uefa, football, team, season]</td>\n",
       "      <td>2008–09 FC Porto season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.101753</td>\n",
       "      <td>-0.087392</td>\n",
       "      <td>0.415259</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>-0.039876</td>\n",
       "      <td>Neoparaphytoseius sooretamus is a species of m...</td>\n",
       "      <td>topic_2</td>\n",
       "      <td>0.415259</td>\n",
       "      <td>[species, gbif, wikidata, col, tree]</td>\n",
       "      <td>Neoparaphytoseius sooretamus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.134862</td>\n",
       "      <td>-0.018495</td>\n",
       "      <td>-0.020146</td>\n",
       "      <td>-0.130587</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>Sengundram known in English as Red Hills is a ...</td>\n",
       "      <td>topic_0</td>\n",
       "      <td>0.134862</td>\n",
       "      <td>[retrieved, historic, national, register, places]</td>\n",
       "      <td>Sengundram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069815</td>\n",
       "      <td>-0.050815</td>\n",
       "      <td>0.230792</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>Eleutherodactylus brevipalmatus Eleutherodacty...</td>\n",
       "      <td>topic_2</td>\n",
       "      <td>0.230792</td>\n",
       "      <td>[species, gbif, wikidata, col, tree]</td>\n",
       "      <td>Eleutherodactylus cuneatus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_0   topic_1   topic_2   topic_3   topic_4  \\\n",
       "0  0.134910 -0.073099  0.005402 -0.054377 -0.021944   \n",
       "1  0.128489 -0.075861 -0.070900  0.242133  0.035059   \n",
       "2  0.101753 -0.087392  0.415259  0.027033 -0.039876   \n",
       "3  0.134862 -0.018495 -0.020146 -0.130587  0.018018   \n",
       "4  0.069815 -0.050815  0.230792  0.000797 -0.022529   \n",
       "\n",
       "                                                text    topic  topic_score  \\\n",
       "0    The Quick and the Dead is a  war film direct...  topic_0     0.134910   \n",
       "1  During the – Portuguese football season FC Por...  topic_3     0.242133   \n",
       "2  Neoparaphytoseius sooretamus is a species of m...  topic_2     0.415259   \n",
       "3  Sengundram known in English as Red Hills is a ...  topic_0     0.134862   \n",
       "4  Eleutherodactylus brevipalmatus Eleutherodacty...  topic_2     0.230792   \n",
       "\n",
       "                                          topic_text  \\\n",
       "0  [retrieved, historic, national, register, places]   \n",
       "1             [league, uefa, football, team, season]   \n",
       "2               [species, gbif, wikidata, col, tree]   \n",
       "3  [retrieved, historic, national, register, places]   \n",
       "4               [species, gbif, wikidata, col, tree]   \n",
       "\n",
       "                           WIKI_TITLE  \n",
       "0  The Quick and the Dead (1963 film)  \n",
       "1             2008–09 FC Porto season  \n",
       "2        Neoparaphytoseius sooretamus  \n",
       "3                          Sengundram  \n",
       "4          Eleutherodactylus cuneatus  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the topic to each document ( Only consider the numerical columns)\n",
    "print(documents_to_topics.columns)\n",
    "documents_to_topics['topic'] = documents_to_topics.idxmax(axis=1, numeric_only=True)\n",
    "documents_to_topics['topic_score'] = documents_to_topics.max(axis=1, numeric_only=True)\n",
    "documents_to_topics['topic_text'] = [list(encoding_matrix.loc[topic].sort_values(ascending=False).index)[:5] for topic in documents_to_topics['topic']]\n",
    "documents_to_topics['WIKI_TITLE'] = titles\n",
    "documents_to_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For example, for the document at index 0, the topic is retrived, history.. natinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Olympics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
